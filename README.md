# Public_LuminaView

## Introduction
[App Store](https://apps.apple.com/kr/app/luminaview/id6737554316)

<img src="https://github.com/user-attachments/assets/0b5ed64b-2c11-4f8a-a0e9-76eb29e0733d" width="100%" />

<p align="center">
  <img src="https://github.com/user-attachments/assets/37c91308-234d-4e8e-ba71-93eaf49ab4c5" width="30%" />  
  <img src="https://github.com/user-attachments/assets/2e1186c3-de21-41ac-80d2-a7fd696cae7f" width="30%" />
  <img src="https://github.com/user-attachments/assets/ce58fa2f-2d62-414e-83d3-2320b4cddd97" width="30%" />
</p>

#### This app is designed to support safe pedestrian navigation for visually impaired individuals.
#### Using the rear camera, the system captures camera data for 5 seconds, then activates voice guidance, supporting all official Apple languages.
#### If the system detects an unsafe walking environment or lacks sufficient reference data, it triggers haptic feedback.

## Contact
#### If you have any feedback, suggestions, or inquiries, please use the address below. We highly value and actively consider your opinions.
- Discord: [Join our community](https://discord.gg/xS6XApRS4p)
- Email: tjdwns6481@naver.com
 
## Upcoming Updates
- Migration from REST Gemini API to Swift Vertex AI Module (Update scope depends on performance testing and caching support).
- UI/UX improvements.
- Refund system implementation.

## System Architecture
<img width="1169" alt="image" src="https://github.com/user-attachments/assets/2d8bded1-2a82-4a86-b7b0-42bec5372988" />
<img width="746" alt="image" src="https://github.com/user-attachments/assets/94ca1276-6be9-40d1-8700-efe1fd6af348" />

## iOS Architecture
### We use Clean Architecture
<img width="1193" alt="image" src="https://github.com/user-attachments/assets/90e64b78-560e-4a8b-b188-86afd489d296" />

